{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "\n",
    "  def __init__(self, size):\n",
    "    self.size = size\n",
    "    self.stack = []\n",
    "\n",
    "  def push(self, item):\n",
    "    if len(self.stack) >= self.size:\n",
    "      self.pop()\n",
    "    self.stack.append(item)\n",
    "\n",
    "  def pop(self):\n",
    "    if self.stack:\n",
    "      return self.stack.pop(0)\n",
    "    else:\n",
    "      return None\n",
    "\n",
    "  def __repr__(self):\n",
    "    return repr(self.stack)\n",
    "  \n",
    "  def copy(self):\n",
    "    return self.stack.copy()\n",
    "  \n",
    "  def __iter__(self):\n",
    "    return iter(self.stack[::-1])\n",
    "  \n",
    "  def full(self):\n",
    "    return len(self.stack) == self.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sweep():\n",
    "  def __init__(self, processes, memory_dim):\n",
    "    self.processes = processes\n",
    "    self.n_processes = len(processes)\n",
    "    self.memory_dim = memory_dim\n",
    "\n",
    "  def make_dict(self):\n",
    "    pass\n",
    "\n",
    "  def get_events(self, sweep_dict, base_process, idx_start, num_events):\n",
    "    curr_process = sweep_dict[base_process]\n",
    "    \n",
    "    if idx_start + num_events > len(self.processes[base_process]):\n",
    "      num_events = len(self.processes[base_process]) - idx_start\n",
    "    \n",
    "    app = [] \n",
    "    for idx in range(idx_start, idx_start + num_events):\n",
    "      for cause in range(self.n_processes):\n",
    "        event = curr_process[cause][idx]\n",
    "        if -1 not in event:\n",
    "          app.append((event, cause))\n",
    "\n",
    "    return DataLoader(app, shuffle = False, batch_size = len(app))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HawkesSweep(Sweep):\n",
    "\n",
    "  def make_dict(self):\n",
    "    dic = {}\n",
    "    for i in range(self.n_processes):\n",
    "      target = self.processes[i]\n",
    "      dic[i] = {}\n",
    "      for j in range(self.n_processes):\n",
    "        cause = self.processes[j]\n",
    "        dic[i][j] = self.sweep(target, cause)\n",
    "\n",
    "    return dic\n",
    "\n",
    "  def sweep(self, pa, pc):\n",
    "    events = []\n",
    "    pa_indices = []\n",
    "\n",
    "    for i, ia in enumerate(pa):\n",
    "      events.append((ia, 'a'))\n",
    "      pa_indices.append(i)\n",
    "\n",
    "    for ic in pc:\n",
    "      events.append((ic, 'c'))\n",
    "\n",
    "    lim = self.memory_dim\n",
    "\n",
    "    events.sort()\n",
    "    mem = Memory(lim)\n",
    "    ret = []\n",
    "\n",
    "    for t, e in events:\n",
    "      if e == 'c':\n",
    "        mem.push(t)\n",
    "\n",
    "      if e == 'a':\n",
    "        # Memory is not full yet\n",
    "        if not mem.full():\n",
    "          pp = [-1] * lim\n",
    "        else:\n",
    "          # Retrieve deltas from this time to the cause times\n",
    "          pp = [t - tc for tc in mem]\n",
    "        ret.append(pp)\n",
    "    return torch.tensor(ret, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk = HawkesSweep([[1, 2, 3], [4, 5, 6]], 2)\n",
    "\n",
    "d = hk.make_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 1.,  2.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.]])},\n",
       " 1: {0: tensor([[1., 2.],\n",
       "          [2., 3.],\n",
       "          [3., 4.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 1.,  2.]])}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = hk.get_events(d, 1, 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [2., 3.],\n",
      "        [3., 4.],\n",
      "        [1., 2.]]) tensor([0, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for _, (X, y) in enumerate(dl):\n",
    "    print (X,y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrangerMPP(nn.Module):\n",
    "\n",
    "    def __init__(self, Process):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.Process = Process\n",
    "        self.n_processes = self.Process.n_processes\n",
    "        self.memory_dim = self.Process.memory_dim\n",
    "        self.GrangerMatrix = nn.Parameter((torch.empty(self.n_processes, self.n_processes)))\n",
    "        nn.init.normal_(self.GrangerMatrix, mean=0.5, std=0.1) \n",
    "\n",
    "        self.models = nn.ModuleList([NormalizingFlow(num_features = 1, memory_size = self.memory_dim, hidden_dim = 32, num_layers = 4) for i in range(self.n_processes)])\n",
    "        self.optimizers = [torch.optim.Adam(list(self.models[i].parameters()), lr=1e-4, weight_decay = 1e-5) for i in range(self.n_processes)]\n",
    "        self.g_optimizer = torch.optim.Adam([self.GrangerMatrix], lr = 1e-3, weight_decay=1e-5)\n",
    "        self.log_GrangerMatrix = []\n",
    "\n",
    "\n",
    "    def em_step(self, n_steps):\n",
    "        \n",
    "        dic = {}\n",
    "        self.causes = [[], [], []]\n",
    "        for i in range(self.n_processes):\n",
    "            dic[i] = []\n",
    "\n",
    "\n",
    "        taus = torch.linspace(1, 0.5, steps = n_steps)\n",
    "        \n",
    "        for self.step in range(n_steps):\n",
    "          for i_proc in range(self.n_processes):\n",
    "              self.causes[i_proc] = []\n",
    "              curr = processes[i_proc]\n",
    "              len_curr = len(curr)\n",
    "              idx_start = 0\n",
    "              while idx_start < len_curr:\n",
    "                self.num_events = 5\n",
    "                events = self.get_events(self.num_events, idx_start, i_proc, 1.0) ## the get_events does the e_step!\n",
    "                if events:\n",
    "                  DL = DataLoader(events, batch_size = len(events))\n",
    "\n",
    "                  for X, cause_rank in DL:\n",
    "                    X = X.unsqueeze(-1)\n",
    "                    loss = self.m_step(i_proc, X, cause_rank)\n",
    "                    dic[i_proc].append(loss)\n",
    "\n",
    "                idx_start += self.num_events\n",
    "\n",
    "              if (self.step + 1) % 5 == 0 or self.step == 0:\n",
    "                  print(f'Step: {self.step + 1}, Model: {i_proc}, Loss: {loss}')\n",
    "\n",
    "\n",
    "        return dic\n",
    "\n",
    "    def m_step(self, i_proc, X, cause_rank):\n",
    "\n",
    "        model = self.models[i_proc]\n",
    "        self.optimizers[i_proc].zero_grad()\n",
    "        self.g_optimizer.zero_grad()\n",
    "        z, logp = model.log_prob(X)\n",
    "        loss = -1*logp\n",
    "\n",
    "        loss_rnn = (loss * cause_rank).sum()  + -1*(torch.log(cause_rank + 1e-7)).sum() + 0.001*self.GrangerMatrix[i_proc].norm(p=1)\n",
    "\n",
    "\n",
    "        if not (torch.isnan(loss_rnn) | torch.isinf(loss_rnn)):\n",
    "\n",
    "\n",
    "            loss_rnn.backward(retain_graph = True)\n",
    "\n",
    "            self.optimizers[i_proc].step()\n",
    "            self.g_optimizer.step()\n",
    "            self.log_GrangerMatrix.append(self.GrangerMatrix.clone().detach())\n",
    "\n",
    "\n",
    "        else:\n",
    "            print(f'NaN found in epoch: {self.step}')\n",
    "\n",
    "        return loss_rnn.item()\n",
    "\n",
    "    def new_e_step(self, num_events, i_proc, tau):\n",
    "\n",
    "      in_ = self.GrangerMatrix[i_proc]#.softmax(dim = 0)\n",
    "      rv = []\n",
    "      for i in range(num_events):\n",
    "        cause = F.gumbel_softmax(\n",
    "            in_,\n",
    "            tau = tau,\n",
    "            hard = False\n",
    "        )\n",
    "        rv.append(cause)\n",
    "\n",
    "      self.causes[i_proc].append(rv)\n",
    "\n",
    "      return rv\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WoldSweep(Sweep):\n",
    "    def construct_wold_dict(self):\n",
    "        dict = {}\n",
    "\n",
    "        events = []\n",
    "        for id, process in enumerate(self.processes):\n",
    "            for t in process:\n",
    "                events.append((t.item(), id))\n",
    "\n",
    "        events.sort()\n",
    "\n",
    "        deltas = {}\n",
    "        last = {}\n",
    "        cur = -1\n",
    "\n",
    "        for t, id in events:\n",
    "            dict[t] = {}\n",
    "            deltas[id] = Memory(self.memory_dim)\n",
    "            last[id] = [0, 0]\n",
    "\n",
    "        for t, id in events:\n",
    "            if t != cur:\n",
    "                \n",
    "                # updating\n",
    "                cur = t\n",
    "                for _id, _delta in deltas.items():\n",
    "                    dict[cur][_id] = _delta.copy()\n",
    "            \n",
    "            last[id][1] = last[id][0]\n",
    "            last[id][0] = t\n",
    "            if last[id][1] != 0:\n",
    "                deltas[id].push(last[id][0] - last[id][1])\n",
    "            \n",
    "        return dict\n",
    "        \n",
    "    # TODO: check idx_start semantics\n",
    "    def make_dict(self):\n",
    "        wold = self.construct_wold_dict()\n",
    "        dic = {}\n",
    "        for i in range(self.n_processes):\n",
    "            target = self.processes[i]\n",
    "            dic[i] = {}\n",
    "            #for j in range(self.n_processes):\n",
    "            #    cause = self.processes[j]\n",
    "            #    dic[i][j] = self.sweep(target, cause)\n",
    "            ret = {}\n",
    "            for _t in target:\n",
    "                t = _t.item()\n",
    "                for j in range(self.n_processes):\n",
    "                    if j not in ret:\n",
    "                        ret[j] = []\n",
    "                    #print(t, j, wold[t][j])\n",
    "                    #return None\n",
    "                    if len(wold[t][j]) < self.memory_dim:\n",
    "                        ret[j].append([-1] * self.memory_dim)\n",
    "                    else:\n",
    "                        ret[j].append(wold[t][j])\n",
    "\n",
    "            #return None\n",
    "            for j in range(self.n_processes):\n",
    "                dic[i][j] = torch.tensor(ret[j], dtype=torch.float)\n",
    "\n",
    "        return dic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.]])},\n",
       " 1: {0: tensor([[-1., -1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.],\n",
       "          [ 1.,  1.]]),\n",
       "  1: tensor([[-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [-1., -1.],\n",
       "          [ 4.,  4.],\n",
       "          [ 4.,  4.]])}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = WoldSweep(torch.tensor([[i for i in range(6)], [i for i in range(0, 6*4, 4)]]), 2)\n",
    "\n",
    "wd.make_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetEvents(Sweep):\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GetEvents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
