{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDB187i0MAsv"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irwZYTpzMKLx"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6939,
     "status": "ok",
     "timestamp": 1710101484335,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "_6W6d1x1ExtJ",
    "outputId": "fdded83a-8a4c-4758-a7ca-79215bde8762"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import pandas as pd\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    torch.set_default_tensor_type(\"torch.FloatTensor\")\n",
    "    device = \"cpu\"\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwYPJGwYExtK"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1710101514627,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "OLwer18YExtN",
    "outputId": "4d79b2b1-76eb-45c1-877b-bb4fa8165ccc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>RATING</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7188</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1407470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>430</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1376539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1369713600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3026</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1350014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3010</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1347854400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24181</th>\n",
       "      <td>7604</td>\n",
       "      <td>7601</td>\n",
       "      <td>10</td>\n",
       "      <td>1364270400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24182</th>\n",
       "      <td>7601</td>\n",
       "      <td>7604</td>\n",
       "      <td>10</td>\n",
       "      <td>1364270400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24183</th>\n",
       "      <td>7604</td>\n",
       "      <td>7602</td>\n",
       "      <td>10</td>\n",
       "      <td>1364270400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24184</th>\n",
       "      <td>7602</td>\n",
       "      <td>7604</td>\n",
       "      <td>10</td>\n",
       "      <td>1364270400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24185</th>\n",
       "      <td>7604</td>\n",
       "      <td>7603</td>\n",
       "      <td>-10</td>\n",
       "      <td>1364270400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24186 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SOURCE  TARGET  RATING        TIME\n",
       "0        7188       1      10  1407470400\n",
       "1         430       1      10  1376539200\n",
       "2        3134       1      10  1369713600\n",
       "3        3026       1      10  1350014400\n",
       "4        3010       1      10  1347854400\n",
       "...       ...     ...     ...         ...\n",
       "24181    7604    7601      10  1364270400\n",
       "24182    7601    7604      10  1364270400\n",
       "24183    7604    7602      10  1364270400\n",
       "24184    7602    7604      10  1364270400\n",
       "24185    7604    7603     -10  1364270400\n",
       "\n",
       "[24186 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"soc-sign-bitcoinalpha.csv\", names=[\"SOURCE\", \"TARGET\", \"RATING\", \"TIME\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1710101543261,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "TnEFlTjn_HoN"
   },
   "outputs": [],
   "source": [
    "df['TIME'] = (df['TIME'] - df['TIME'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710101849027,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "p30qBJW_ASnf"
   },
   "outputs": [],
   "source": [
    "mean = df['TIME'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710101853733,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "H9e2L7r2_HoN"
   },
   "outputs": [],
   "source": [
    "teste = df.query(f'TIME <= {mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710101860952,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "SEf2nXjNA36N",
    "outputId": "11f01979-9abb-4a9b-84e7-d0e1d53ba757"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12485"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1710101998231,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "DHENGzGKACmE"
   },
   "outputs": [],
   "source": [
    "# plt.hist(df['TIME'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZcZVztYLHtx"
   },
   "source": [
    "# Modelo usando SOURCE\n",
    "\n",
    "A principio, vamos tentar modelar ignorando os targets e os ratings. Nesse caso, estamos considerando a sequencia de ratings de cada source uma avaliacao do TPP. Dessa forma, esperamos que o modelo aprenda como uma unica source realiza seus ratings no tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1710101924095,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "7_aY6bz0I4Al",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['SOURCE'])['TIME'].apply(list).reset_index(name='TIMES_PRE')\n",
    "def foo(ls):\n",
    "    threshold = 1.25e8\n",
    "    return [x for x in ls if x <= threshold]\n",
    "grouped['TIMES'] = grouped['TIMES_PRE'].apply(lambda ts : foo(ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1710101942830,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "Gu3SzFBE_HoO",
    "outputId": "45dcf6f5-f513-41b5-9b78-d9663cb29372"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>TIMES_PRE</th>\n",
       "      <th>TIMES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[27990000, 59612400, 89161200, 82854000, 81644...</td>\n",
       "      <td>[27990000, 59612400, 89161200, 82854000, 81644...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[122770800, 53910000, 105231600, 1728000, 9072...</td>\n",
       "      <td>[122770800, 53910000, 105231600, 1728000, 9072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[83804400, 65836800, 72748800, 103075200, 7568...</td>\n",
       "      <td>[83804400, 65836800, 72748800, 103075200, 7568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[10454400, 9072000, 20127600, 12697200, 482076...</td>\n",
       "      <td>[10454400, 9072000, 20127600, 12697200, 482076...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[97977600, 94435200, 91234800, 96249600, 80953...</td>\n",
       "      <td>[97977600, 94435200, 91234800, 96249600, 80953...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SOURCE                                          TIMES_PRE  \\\n",
       "0       1  [27990000, 59612400, 89161200, 82854000, 81644...   \n",
       "1       2  [122770800, 53910000, 105231600, 1728000, 9072...   \n",
       "2       3  [83804400, 65836800, 72748800, 103075200, 7568...   \n",
       "3       4  [10454400, 9072000, 20127600, 12697200, 482076...   \n",
       "4       5  [97977600, 94435200, 91234800, 96249600, 80953...   \n",
       "\n",
       "                                               TIMES  \n",
       "0  [27990000, 59612400, 89161200, 82854000, 81644...  \n",
       "1  [122770800, 53910000, 105231600, 1728000, 9072...  \n",
       "2  [83804400, 65836800, 72748800, 103075200, 7568...  \n",
       "3  [10454400, 9072000, 20127600, 12697200, 482076...  \n",
       "4  [97977600, 94435200, 91234800, 96249600, 80953...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1710102292254,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "OZR-HqcELVl9",
    "outputId": "9e83bcc0-10e5-4c81-b1fb-d2f6a7bc0deb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124758000\n"
     ]
    }
   ],
   "source": [
    "def get_inter_times(t, t_end):\n",
    "    t.sort()\n",
    "    tau = np.diff(t, prepend=0.0, append=t_end)\n",
    "    return torch.tensor(tau, dtype=torch.float32, device=device)\n",
    "\n",
    "t_ends = torch.tensor([\n",
    "    torch.tensor(l[-1], dtype=torch.long, device=device) for l in grouped['TIMES'].values if len(l) > 0])\n",
    "print(t_ends.max().item())\n",
    "t_end = t_ends.max().item() #+ 1e8\n",
    "seq_lengths = torch.tensor(\n",
    "    [len(t) for t in grouped['TIMES'].values], dtype=torch.long\n",
    ")  # (B,)\n",
    "rating_times_list = [get_inter_times(x, t_end) for x in grouped['TIMES'].values]\n",
    "rating_times = pad_sequence(rating_times_list, batch_first=True)  # (B, L)\n",
    "\n",
    "## important\n",
    "\n",
    "t_end = t_ends.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ua-vRcJJ_HoP"
   },
   "source": [
    "Para o `t_end`, estou utilizando o maior valor de timestamp da base de dados + $10^8$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710102901746,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "dmKDhz7kbUCJ",
    "outputId": "99e457da-dcd9-45fb-ed82-428b32756bc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3286, 477])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710103379562,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "OzG2awOJGnoT",
    "outputId": "6bc758d1-31af-48d1-bb63-4b6fe93dad03"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munique_values\u001b[49m\u001b[38;5;241m.\u001b[39mshape, counts\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_values' is not defined"
     ]
    }
   ],
   "source": [
    "unique_values.shape, counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710103393211,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "L5jZ3DnLGtHF",
    "outputId": "104f9c57-1c13-4316-b896-7642e2b506f3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sorted_values, sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msort(\u001b[43munique_values\u001b[49m)\n\u001b[1;32m      2\u001b[0m sorted_values\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'unique_values' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_values, sorted_indices = torch.sort(unique_values)\n",
    "sorted_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "error",
     "timestamp": 1710103439237,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "Wp4LSIjTEHeh",
    "outputId": "c047ffe3-ff31-4f3a-b73c-56e20370541d"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of ellipsis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Your 2D tensor with 1247 unique values\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m tensor_2d \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                          \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace ... with your values\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Flatten the tensor\u001b[39;00m\n\u001b[1;32m      9\u001b[0m flattened_tensor \u001b[38;5;241m=\u001b[39m tensor_2d\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of ellipsis"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Your 2D tensor with 1247 unique values\n",
    "tensor_2d = torch.tensor([[5, 12, 3],\n",
    "                          [8, 2, 15],\n",
    "                          ...])  # Replace ... with your values\n",
    "\n",
    "# Flatten the tensor\n",
    "flattened_tensor = tensor_2d.flatten()\n",
    "\n",
    "# Get unique values and their counts\n",
    "unique_values, counts = torch.unique(flattened_tensor, return_counts=True)\n",
    "\n",
    "# Sort unique values\n",
    "sorted_values, sorted_indices = torch.sort(unique_values)\n",
    "\n",
    "# Create a dictionary to map each value to its index\n",
    "index_map = {value.item(): index.item() for value, index in zip(sorted_values, sorted_indices)}\n",
    "\n",
    "# Map values to indices\n",
    "mapped_indices = torch.tensor([index_map[value.item()] for value in flattened_tensor])\n",
    "\n",
    "# Reshape the mapped indices back to the original shape\n",
    "mapped_indices_2d = mapped_indices.view(tensor_2d.size())\n",
    "\n",
    "print(mapped_indices_2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 248,
     "status": "ok",
     "timestamp": 1710103086121,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "kV7aQ3rBE8kx",
    "outputId": "72eb096f-7c2b-446f-81d5-62fb1d751d2f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sorted_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msorted_indices\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sorted_indices' is not defined"
     ]
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tacDYgK6ExtO"
   },
   "source": [
    "## Choose a parametric distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1710102292255,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "H5-wCm6TExtO"
   },
   "outputs": [],
   "source": [
    "class Weibull:\n",
    "    \"\"\"Weibull distribution.\n",
    "\n",
    "    Args:\n",
    "        b: scale parameter b (strictly positive)\n",
    "        k: shape parameter k (strictly positive)\n",
    "        eps: Minimum value of x, used for numerical stability.\n",
    "    \"\"\"\n",
    "    def __init__(self, b, k, eps=1e-8):\n",
    "        self.b = b\n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        \"\"\"Logarithm of the probability density function log(f(x)).\"\"\"\n",
    "        # x must have the same shape as self.b and self.k\n",
    "        x = x.clamp_min(self.eps)  # pow is unstable for inputs close to 0\n",
    "        return (self.b.log() + self.k.log() + (self.k - 1) * x.log()\n",
    "                + self.b.neg() * torch.pow(x, self.k))\n",
    "\n",
    "    def log_survival(self, x):\n",
    "        \"\"\"Logarithm of the survival function log(S(x)).\"\"\"\n",
    "        x = x.clamp_min(self.eps)\n",
    "        return self.b.neg() * torch.pow(x, self.k)\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        \"\"\"Generate a sample from the distribution.\"\"\"\n",
    "        # We do sampling using the inverse transform method\n",
    "        # If z ~ Expo(1), then solving exp(-z) = S(x) for x produces\n",
    "        # a sample from the distribution with survival function S\n",
    "        shape = torch.Size(sample_shape) + self.b.shape\n",
    "        z = torch.empty(shape).exponential_(1.0)\n",
    "        return (z * self.b.reciprocal() + self.eps).pow(self.k.reciprocal())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D19hnkxDExtQ"
   },
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1710102292939,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "-vfUBUV0ExtQ"
   },
   "outputs": [],
   "source": [
    "class NeuralTPP(nn.Module):\n",
    "    \"\"\"A simple neural TPP model with an RNN encoder.\n",
    "\n",
    "    Args:\n",
    "        context_size: Size of the RNN hidden state.\n",
    "    \"\"\"\n",
    "    def __init__(self, context_size=32):\n",
    "        super().__init__()\n",
    "        self.context_size = context_size\n",
    "        # Used to embed the event history into a context vector\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=2,\n",
    "            hidden_size=context_size,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # Used to obtain model parameters from the context vector\n",
    "        self.hypernet = nn.Linear(\n",
    "            in_features=context_size,\n",
    "            out_features=2,\n",
    "        )\n",
    "\n",
    "    def get_context(self, inter_times):\n",
    "        \"\"\"Get context embedding for each event in each sequence.\n",
    "\n",
    "        Args:\n",
    "            inter_times: Padded inter-event times, shape (B, L)\n",
    "\n",
    "        Returns:\n",
    "            context: Context vectors, shape (B, L, C)\n",
    "        \"\"\"\n",
    "        tau = inter_times.unsqueeze(-1)\n",
    "        # Clamp tau to avoid computing log(0) for padding and getting NaNs\n",
    "        log_tau = inter_times.clamp_min(1e-8).log().unsqueeze(-1)  # (B, L, 1)\n",
    "        rnn_input = torch.cat([tau, log_tau], dim=-1)\n",
    "        # The intial state is automatically set to zeros\n",
    "        rnn_output = self.rnn(rnn_input)[0]  # (B, L, C)\n",
    "        # Shift by one such that context[:, i] will be used\n",
    "        # to parametrize the distribution of inter_times[:, i]\n",
    "        context = F.pad(rnn_output[:, :-1, :], (0, 0, 1, 0))  # (B, L, C)\n",
    "        return context\n",
    "\n",
    "    def get_inter_time_distribution(self, context):\n",
    "        \"\"\"Get context embedding for each event in each sequence.\n",
    "\n",
    "        Args:\n",
    "            context: Context vectors, shape (B, L, C)\n",
    "\n",
    "        Returns:\n",
    "            dist: Conditional distribution over the inter-event times\n",
    "        \"\"\"\n",
    "        raw_params = self.hypernet(context)  # (B, L, 2)\n",
    "        b = F.softplus(raw_params[..., 0])  # (B, L)\n",
    "        k = F.softplus(raw_params[..., 1])  # (B, L)\n",
    "        return Weibull(b=b, k=k)\n",
    "\n",
    "    def nll_loss(self, inter_times, seq_lengths):\n",
    "        \"\"\"Compute negative log-likelihood for a batch of sequences.\n",
    "\n",
    "        Args:\n",
    "            inter_times: Padded inter_event times, shape (B, L)\n",
    "            seq_lengths: Number of events in each sequence, shape (B,)\n",
    "\n",
    "        Returns:\n",
    "            log_p: Log-likelihood for each sequence, shape (B,)\n",
    "        \"\"\"\n",
    "        context = self.get_context(inter_times)  # (B, L, C)\n",
    "        inter_time_dist = self.get_inter_time_distribution(context)\n",
    "\n",
    "        log_pdf = inter_time_dist.log_prob(inter_times)  # (B, L)\n",
    "        # Construct a boolean mask that selects observed events\n",
    "        arange = torch.arange(inter_times.shape[1], device=seq_lengths.device)\n",
    "        mask = (arange[None, :] < seq_lengths[:, None]).float()  # (B, L)\n",
    "        log_like = (log_pdf * mask).sum(-1)  # (B,)\n",
    "\n",
    "        log_surv = inter_time_dist.log_survival(inter_times)  # (B, L)\n",
    "        end_idx = seq_lengths.unsqueeze(-1)  # (B, 1)\n",
    "        log_surv_last = torch.gather(log_surv, dim=-1, index=end_idx)  # (B, 1)\n",
    "        log_like += log_surv_last.squeeze(-1)  # (B,)\n",
    "        return -log_like\n",
    "\n",
    "    def sample(self, batch_size, t_end):\n",
    "        \"\"\"Generate an event sequence from the TPP.\n",
    "\n",
    "        Args:\n",
    "            batch_size: Number of samples to generate in parallel.\n",
    "            t_end: Time until which the TPP is simulated.\n",
    "\n",
    "        Returns:\n",
    "            inter_times: Padded inter-event times, shape (B, L)\n",
    "            seq_lengths: Number of events in each sequence, shape (B,)\n",
    "        \"\"\"\n",
    "        inter_times = torch.empty([batch_size, 0])\n",
    "        next_context = torch.zeros(batch_size, 1, self.context_size)\n",
    "        generated = False\n",
    "        while not generated:\n",
    "            inter_time_dist = self.get_inter_time_distribution(next_context)\n",
    "            next_inter_times = inter_time_dist.sample()  # (B, 1)\n",
    "            inter_times = torch.cat([inter_times, next_inter_times], dim=1)  # (B, L)\n",
    "\n",
    "            # Obtain the next context vector\n",
    "            tau = next_inter_times.unsqueeze(-1)  # (B, 1, 1)\n",
    "            log_tau = next_inter_times.clamp_min(1e-8).log().unsqueeze(-1)  # (B, 1, 1)\n",
    "            rnn_input = torch.cat([tau, log_tau], dim=-1)  # (B, 1, 2)\n",
    "            next_context = self.rnn(rnn_input, next_context.transpose(0, 1))[0]  # (B, 1, C)\n",
    "\n",
    "            # Check if the end of the interval has been reached#\n",
    "            generated = inter_times.sum(-1).min() >= t_end\n",
    "        # Convert the sample to their same format as our input data\n",
    "        arrival_times = inter_times.cumsum(-1)\n",
    "        seq_lengths = (arrival_times < t_end).sum(-1).long()\n",
    "        inter_times = arrival_times - F.pad(arrival_times, (1, 0))[..., :-1]\n",
    "        return inter_times, seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1710102294113,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "BQDzJX8RCACU"
   },
   "outputs": [],
   "source": [
    "a, b = torch.sort(rating_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-v3M0LLExtR"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28671,
     "status": "ok",
     "timestamp": 1710102333550,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "g2Z8nHUqExtS",
    "outputId": "63f76205-826c-4700-c242-5b161b934d2f"
   },
   "outputs": [],
   "source": [
    "model = NeuralTPP()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_epochs = 300\n",
    "for epoch in range(max_epochs + 1):\n",
    "    opt.zero_grad()\n",
    "    loss = model.nll_loss(a, seq_lengths).mean() / t_end\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1710102376620,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "dlY5YYIwC0kW",
    "outputId": "7a1b6668-c9b4-4a6f-df11-b66f6a313245"
   },
   "outputs": [],
   "source": [
    "t_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBIezmJoExtU"
   },
   "source": [
    "## Sample event sequences from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1710102585339,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "Kl8JlmSZExtV"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gen_inter_times, gen_seq_lengths = model.sample(1000, 5) #t_end\n",
    "gen_arrival_times = gen_inter_times.cumsum(-1)\n",
    "generated_sequences = []\n",
    "for i in range(gen_arrival_times.shape[0]):\n",
    "    t = gen_arrival_times[i, :gen_seq_lengths[i]].cpu().numpy()\n",
    "    generated_sequences.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "executionInfo": {
     "elapsed": 2134,
     "status": "ok",
     "timestamp": 1710102596409,
     "user": {
      "displayName": "tho3n kip",
      "userId": "14332135687314860837"
     },
     "user_tz": 180
    },
    "id": "32PtOlbLExtV",
    "outputId": "f6a59ada-73e1-4bde-8233-bd0923b9f725"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=[8, 4.5], dpi=200, nrows=2, ncols=2)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for idx, t in enumerate(rating_times_list[:10]):\n",
    "    axes[0, 0].scatter(t.cpu(), np.ones_like(t.cpu()) * idx, alpha=0.5, c='C0', marker=\"|\")\n",
    "axes[0, 0].set_ylabel(\"Real sequence #\", fontsize=7)\n",
    "axes[0, 0].set_yticks(np.arange(10));\n",
    "axes[0, 0].set_title(\"Visualization of arrival times\", fontsize=9)\n",
    "\n",
    "\n",
    "for idx, t in enumerate(generated_sequences[:10]):\n",
    "    axes[1, 0].scatter(t, np.ones_like(t) * idx, alpha=0.5, c='C1', marker=\"|\")\n",
    "axes[1, 0].set_xlabel(\"Time\", fontsize=7)\n",
    "axes[1, 0].set_ylabel(\"Generated sequence #\", fontsize=7)\n",
    "axes[1, 0].set_yticks(np.arange(10))\n",
    "axes[0, 0].set_xticklabels([])\n",
    "\n",
    "for ax in np.ravel(axes):\n",
    "    ax.tick_params(axis='x', labelsize=7)\n",
    "    ax.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "axes[0, 1].set_title(\"Distribution of sequence lengths\", fontsize=9)\n",
    "q_min = min(seq_lengths.min(), gen_seq_lengths.min())\n",
    "q_max = max(seq_lengths.max(), gen_seq_lengths.max())\n",
    "axes[0, 1].hist(seq_lengths, 30, alpha=0.8, color=\"C0\", range=(q_min, q_max), label=\"Real data\");\n",
    "axes[0, 1].set_ylabel(\"Frequency\", fontsize=7)\n",
    "axes[0, 1].set_xticklabels([])\n",
    "\n",
    "axes[1, 1].hist(gen_seq_lengths, 30, alpha=0.8, color=\"C1\", range=(q_min, q_max), label=\"Generated by the model\");\n",
    "axes[1, 1].set_xlabel(r\"Sequence length\", fontsize=7)\n",
    "axes[1, 1].set_ylabel(\"Frequency\", fontsize=7)\n",
    "\n",
    "fig.legend(loc=\"lower center\", ncol=2, fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5C1C4uoR55_"
   },
   "source": [
    "# Modelo usando TARGET\n",
    "\n",
    "Agora vamos considerar a sequência de ratings de cada target uma avaliação do TPP. Dessa forma, esperamos que o modelo aprenda como um único target recebe ratings no tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8C0Y53gVSAO5",
    "outputId": "31bb4cc5-ba04-4e65-b585-398c6240de51"
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(['TARGET'])['TIME'].apply(list).reset_index(name='TIMES')\n",
    "grouped['TIMES'].values[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRgJdg30vK9y",
    "outputId": "973aadce-8a20-49d9-9656-d8e10c8f4f03"
   },
   "outputs": [],
   "source": [
    "def get_inter_times(t, t_end):\n",
    "    t.sort()\n",
    "    tau = np.diff(t, prepend=0.0, append=t_end)\n",
    "    return torch.tensor(tau, dtype=torch.float32, device=device)\n",
    "\n",
    "t_ends = torch.tensor([\n",
    "    torch.tensor(l[-1], dtype=torch.long, device=device) for l in grouped['TIMES'].values\n",
    "])\n",
    "print(t_ends.max().item())\n",
    "t_end = t_ends.max().item() + 1e8\n",
    "print(t_end)\n",
    "#t_end = 2000000000\n",
    "seq_lengths = torch.tensor(\n",
    "    [len(t) for t in grouped['TIMES'].values], dtype=torch.long\n",
    ")  # (B,)\n",
    "rating_times_list = [get_inter_times(x, t_end) for x in grouped['TIMES'].values]\n",
    "rating_times = pad_sequence(rating_times_list, batch_first=True)  # (B, L)\n",
    "print(len(rating_times[0]))\n",
    "print(seq_lengths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9YYqIXPRvTA5",
    "outputId": "aeb579db-6b87-4056-dbe1-b549c6e5489c"
   },
   "outputs": [],
   "source": [
    "model = NeuralTPP()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-3)\n",
    "\n",
    "max_epochs = 150\n",
    "for epoch in range(max_epochs + 1):\n",
    "    opt.zero_grad()\n",
    "    loss = model.nll_loss(rating_times, seq_lengths).mean() / t_end\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "snMuenJZvbaQ"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    gen_inter_times, gen_seq_lengths = model.sample(1000, t_end)\n",
    "gen_arrival_times = gen_inter_times.cumsum(-1)\n",
    "generated_sequences = []\n",
    "for i in range(gen_arrival_times.shape[0]):\n",
    "    t = gen_arrival_times[i, :gen_seq_lengths[i]].cpu().numpy()\n",
    "    generated_sequences.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4qiZ51z9veep"
   },
   "outputs": [],
   "source": [
    "seq_lengths = seq_lengths.cpu().numpy()\n",
    "gen_seq_lengths = gen_seq_lengths.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hr29lX5Xvjex",
    "outputId": "59f2938c-fc12-4131-eed3-9d0ba9582ac5"
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "fig, axes = plt.subplots(figsize=[8, 4.5], dpi=200, nrows=2, ncols=2)\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "for idx, t in enumerate(rating_times_list[:N]):\n",
    "    axes[0, 0].scatter(t.cpu(), np.ones_like(t.cpu()) * idx, alpha=0.5, c='C0', marker=\"|\")\n",
    "axes[0, 0].set_ylabel(\"Real sequence #\", fontsize=7)\n",
    "axes[0, 0].set_yticks(np.arange(N));\n",
    "axes[0, 0].set_title(\"Visualization of arrival times\", fontsize=9)\n",
    "\n",
    "\n",
    "for idx, t in enumerate(generated_sequences[:N]):\n",
    "    axes[1, 0].scatter(t, np.ones_like(t) * idx, alpha=0.5, c='C1', marker=\"|\")\n",
    "axes[1, 0].set_xlabel(\"Time\", fontsize=7)\n",
    "axes[1, 0].set_ylabel(\"Generated sequence #\", fontsize=7)\n",
    "axes[1, 0].set_yticks(np.arange(N))\n",
    "axes[0, 0].set_xticklabels([])\n",
    "\n",
    "for ax in np.ravel(axes):\n",
    "    ax.tick_params(axis='x', labelsize=7)\n",
    "    ax.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "axes[0, 1].set_title(\"Distribution of sequence lengths\", fontsize=9)\n",
    "q_min = min(seq_lengths.min(), gen_seq_lengths.min())\n",
    "q_max = max(seq_lengths.max(), gen_seq_lengths.max())\n",
    "axes[0, 1].hist(seq_lengths, 30, alpha=0.8, color=\"C0\", range=(q_min, q_max), label=\"Real data\");\n",
    "axes[0, 1].set_ylabel(\"Frequency\", fontsize=7)\n",
    "axes[0, 1].set_xticklabels([])\n",
    "\n",
    "axes[1, 1].hist(gen_seq_lengths, 30, alpha=0.8, color=\"C1\", range=(q_min, q_max), label=\"Generated by the model\");\n",
    "axes[1, 1].set_xlabel(r\"Sequence length\", fontsize=7)\n",
    "axes[1, 1].set_ylabel(\"Frequency\", fontsize=7)\n",
    "\n",
    "fig.legend(loc=\"lower center\", ncol=2, fontsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77U86tEt_HoS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "BZcZVztYLHtx",
    "M5C1C4uoR55_"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
